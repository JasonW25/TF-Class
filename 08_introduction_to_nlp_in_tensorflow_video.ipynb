{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/mrdbourke/tensorflow-deep-learning/blob/main/video_notebooks/08_introduction_to_nlp_in_tensorflow_video.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VkhpvcnZiNkb"
   },
   "source": [
    "# Introduction to NLP Fundamentals in TensorFlow\n",
    "\n",
    "NLP has the goal of deriving informaton out of natural language (could be seqeuences text or speech).\n",
    "\n",
    "Another common term for NLP problems is sequence to sequence problems (seq2seq).\n",
    "\n",
    "> üìñ **Resource:** See all course materials, resources and extra-curriculum for this notebook on GitHub: https://github.com/mrdbourke/tensorflow-deep-learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F251SjqZimVF"
   },
   "source": [
    "## Check for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m1dVFu5Jis9Z",
    "outputId": "6b269000-e2b8-4bee-8d65-447ef3a20986"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA GeForce RTX 3060 (UUID: GPU-d22cf328-24d9-d90f-558f-f3ed7223ea38)\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9qrnNJ_4iuX-"
   },
   "source": [
    "## Get helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xC2eRi-Ti6Bt",
    "outputId": "fd95b8a9-8639-472f-dd5e-fd9fc348fb00"
   },
   "outputs": [],
   "source": [
    "# !wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
    "\n",
    "# Import series of helper functions for the notebook\n",
    "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x8MQn_DwjSlJ"
   },
   "source": [
    "## Get a text dataset\n",
    "\n",
    "The dataset we're going to be using is Kaggle's introduction to NLP dataset (text samples of Tweets labelled as diaster or not diaster).\n",
    "\n",
    "See the original source here: https://www.kaggle.com/c/nlp-getting-started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XuFNZ6zvjW-J",
    "outputId": "8c7a1370-f981-4875-ac12-f79338125c1c"
   },
   "outputs": [],
   "source": [
    "# !wget https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
    "\n",
    "# # Unzip data\n",
    "# unzip_data(\"nlp_getting_started.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-I5zOcnvj4NO"
   },
   "source": [
    "## Visualizing a text dataset\n",
    "\n",
    "To visualize our text samples, we first have to read them in, one way to do so would be to use Python: https://realpython.com/read-write-files-python/\n",
    "\n",
    "But I prefer to get visual straight away.\n",
    "\n",
    "So another way to do this is to use pandas..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "WMK3xqK8kqQL",
    "outputId": "168211c3-3ea1-4ef0-ec33-0466fc488366"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv(\"nlp_getting_started/train.csv\")\n",
    "test_df = pd.read_csv(\"nlp_getting_started/test.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "ng4p6stElbl4",
    "outputId": "a9640765-8a02-46fd-a3b2-015f47070cff"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>3796</td>\n",
       "      <td>destruction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>So you have a new weapon that can cause un-ima...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>3185</td>\n",
       "      <td>deluge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5448</th>\n",
       "      <td>7769</td>\n",
       "      <td>police</td>\n",
       "      <td>UK</td>\n",
       "      <td>DT @georgegalloway: RT @Galloway4Mayor: ¬â√õ√èThe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>191</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aftershock back to school kick off was great. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6845</th>\n",
       "      <td>9810</td>\n",
       "      <td>trauma</td>\n",
       "      <td>Montgomery County, MD</td>\n",
       "      <td>in response to trauma Children of Addicts deve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id      keyword               location  \\\n",
       "2644  3796  destruction                    NaN   \n",
       "2227  3185       deluge                    NaN   \n",
       "5448  7769       police                     UK   \n",
       "132    191   aftershock                    NaN   \n",
       "6845  9810       trauma  Montgomery County, MD   \n",
       "\n",
       "                                                   text  target  \n",
       "2644  So you have a new weapon that can cause un-ima...       1  \n",
       "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
       "5448  DT @georgegalloway: RT @Galloway4Mayor: ¬â√õ√èThe...       1  \n",
       "132   Aftershock back to school kick off was great. ...       0  \n",
       "6845  in response to trauma Children of Addicts deve...       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle training dataframe\n",
    "train_df_shuffled = train_df.sample(frac=1, random_state=42) \n",
    "train_df_shuffled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "dBUTSefKljdb",
    "outputId": "6ebbf625-3331-4043-9a64-fc688ca6eed1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What does the test dataframe look like?\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4rCFdfq7mJGs",
    "outputId": "42bbb29d-d22a-4bcc-8295-f7f098d8e06a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4342\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many examples of each class?\n",
    "train_df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h5wrCzWCmS9P",
    "outputId": "50cd45e1-4faf-4d7e-827c-7fc00415688f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 3263)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many total samples?\n",
    "len(train_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IHqct-_WmzSp",
    "outputId": "b7a07218-9cb6-4a52-d129-0de5644064f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 1 (real diaster)\n",
      "Text:\n",
      "The people who tweet and care about #Japan #Fukushima nuclear disaster are not the problem those who ignore are the problem.\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0 (not real diaster)\n",
      "Text:\n",
      "Timestack' Photos Collapse Entire Sunsets Into Single Mesmerizing Images. http://t.co/Cas8xC2DFE\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0 (not real diaster)\n",
      "Text:\n",
      "#handbag #fashion #style http://t.co/hPd3SNM6oy Vintage Coach Purse Camera Bag Cross Body #9973\n",
      "\n",
      "$16.99 (0 Bids)\n",
      "¬â√õ_ http://t.co/GSmdDmu9Pu\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0 (not real diaster)\n",
      "Text:\n",
      "Success is not permanent &amp; failure is not fatal.\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0 (not real diaster)\n",
      "Text:\n",
      "You made my mood go from shitty af to panicking af istg\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's visualize some random training examples\n",
    "import random\n",
    "random_index = random.randint(0, len(train_df)-5) # create random indexes not higher than the total number of samples\n",
    "for row in train_df_shuffled[[\"text\", \"target\"]][random_index:random_index+5].itertuples():\n",
    "  _, text, target = row\n",
    "  print(f\"Target: {target}\", \"(real diaster)\" if target > 0 else \"(not real diaster)\")\n",
    "  print(f\"Text:\\n{text}\\n\")\n",
    "  print(\"---\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cZEKNKZOn0A8"
   },
   "source": [
    "### Split data into training and validation sets\n",
    "\n",
    "We want to be able to see how our model is performing on unseen data whilst it trains.\n",
    "\n",
    "And because the testing dataset doesn't have labels, we'll have to create a validation dataset to evaluate on (the model won't see the validation dataset during training so we can use its samples and labels to evaluate our model's performance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "RRurDp_XpEv_"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "kBSr2LTvpRQm"
   },
   "outputs": [],
   "source": [
    "# Use train_test_split to split training data into training and validation sets\n",
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
    "                                                                            train_df_shuffled[\"target\"].to_numpy(),\n",
    "                                                                            test_size=0.1, # use 10% of training data for validation split\n",
    "                                                                            random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AxpYGpF5pxiM",
    "outputId": "dff90d32-2ec1-4e81-d32d-87a697334383"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6851, 6851, 762, 762)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the lengths\n",
    "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m1xC2MWxp5Rj",
    "outputId": "e5421f13-8871-4fc5-87d0-cff426878e99"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
       "        'Imagine getting flattened by Kurt Zouma',\n",
       "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
       "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
       "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
       "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
       "        'destroy the free fandom honestly',\n",
       "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
       "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
       "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
       "       dtype=object),\n",
       " array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the first 10 samples \n",
    "train_sentences[:10], train_labels[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Td1h4t5p7ST"
   },
   "source": [
    "## Converting text into numbers\n",
    "\n",
    "When dealing with a text problem, one of the first things you'll have to do before you can build a model is to convert your text to numbers.\n",
    "\n",
    "There are a few ways to do this, namely:\n",
    "* Tokenziation - direct mapping of token (a token could be a word or a character) to number\n",
    "* Embedding - create a matrix of feature vector for each token (the size of the feature vector can be defined and this embedding can be learned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BI3K0U_xBtu6"
   },
   "source": [
    "### Text vectorization (tokenization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I_hj9h10FJ56",
    "outputId": "ef9dd7f7-2f60-4d34-8fc4-57ceb83ffa51"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
       "       'Imagine getting flattened by Kurt Zouma',\n",
       "       '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
       "       \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
       "       'Somehow find you and I collide http://t.co/Ee8RpOahPk'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "blJWemjwFIP-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3060, compute capability 8.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-07 18:12:47.295499: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-07 18:12:47.329991: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-07 18:12:47.330156: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-07 18:12:47.330690: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-07 18:12:47.336339: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-07 18:12:47.337082: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-07 18:12:47.337247: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-07 18:12:47.337369: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-07 18:12:47.658666: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-07 18:12:47.658832: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-07 18:12:47.658963: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-07 18:12:47.659065: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10144 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:29:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import mixed_precision\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "# Use the default TextVectorization parameters\n",
    "text_vectorizer = TextVectorization(max_tokens=None, # how many words in the vocabulary (automatically add <OOV>)\n",
    "                                    standardize=\"lower_and_strip_punctuation\",\n",
    "                                    split=\"whitespace\",\n",
    "                                    ngrams=None, # create groups of n-words?\n",
    "                                    output_mode=\"int\", # how to map tokens to numbers\n",
    "                                    output_sequence_length=None, # how long do you want your sequences to be?\n",
    "                                    pad_to_max_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_wxF2xv-H4xB",
    "outputId": "f84230f1-69fe-4c34-f3ef-bc2784d8ab2f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sentences[0].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YjPouAI-FR0c",
    "outputId": "2269c697-5b8d-446b-b256-5a6ff675600b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the average number of tokens (words) in the training tweets\n",
    "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "fPPKoQ2uIBuY"
   },
   "outputs": [],
   "source": [
    "# Setup text vectorization variables\n",
    "max_vocab_length = 10000 # max number of words to have in our vocabulary\n",
    "max_length = 15 # max length our sequences will be (e.g. how many words from a Tweet does a model see?)\n",
    "\n",
    "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
    "                                    output_mode=\"int\",\n",
    "                                    output_sequence_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "s5TD-rndImmo"
   },
   "outputs": [],
   "source": [
    "# Fit the text vectorizer instance to the training data using the adapt() method\n",
    "text_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R-ETwZ92JiOx",
    "outputId": "98a580db-6f26-4275-b39f-ca09e8084e26"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[264,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]])>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a sample sentence and tokenize it\n",
    "sample_sentence = \"There's a flood in my street!\"\n",
    "text_vectorizer([sample_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CtG-XWMHJ9Zi",
    "outputId": "5723dbe6-c5fa-4be7-d3b1-930138530818"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "@ThomasHCrown My grandfather was set to be in the first groups of Marines to hit Japan in Operation Olympic. 95% casualty rate predictions        \n",
      "\n",
      "Vectorized version:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[7602,   13,    1,   23,  284,    5,   21,    4,    2,   97, 2972,\n",
       "           6, 5165,    5,  244]])>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a random sentence from the training dataset and tokenize it\n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(f\"Original text:\\n{random_sentence}\\\n",
    "        \\n\\nVectorized version:\")\n",
    "text_vectorizer([random_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "np2kAsmlKk13",
    "outputId": "dbf73060-1cdd-465a-ddad-f6f618a75c34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common words in vocab: ['', '[UNK]', 'the', 'a', 'in']\n",
      "Least common words in vocab: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
     ]
    }
   ],
   "source": [
    "# Get the unique words in the vocabulary\n",
    "words_in_vocab = text_vectorizer.get_vocabulary()\n",
    "top_5_words = words_in_vocab[:5] # the most common words in the vocab\n",
    "bottom_5_words = words_in_vocab[-5:] # the least common words in the vocab\n",
    "print(f\"Most common words in vocab: {top_5_words}\")\n",
    "print(f\"Least common words in vocab: {bottom_5_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w2Kk1wTIK8CV",
    "outputId": "0fa8489c-c27b-43d1-dff8-2ace2d6f03d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how long is our vocab?\n",
    "len(words_in_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rn3N5uRPLAvm"
   },
   "source": [
    "## Creating an Embedding using an Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FLdTzqnVe_2i",
    "outputId": "075cdba4-ff3b-4e28-a97b-ce5364fbe006"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ty5Y34oQMPi8",
    "outputId": "96ff99e2-310f-4c59-94eb-fc7360919119"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.embeddings.Embedding at 0x7f497c28c7c0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import layers \n",
    "\n",
    "embedding = layers.Embedding(input_dim=max_vocab_length, # set the input shape\n",
    "                             output_dim=128, # set the size of the embedding vector\n",
    "                             embeddings_initializer=\"uniform\", # default, initialize embedding vectors randomly\n",
    "                             input_length=max_length # how long is each input\n",
    "                             )\n",
    "\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ThScOvPANZzB",
    "outputId": "1fa3fc2d-87f9-472f-a8c6-d73de4004ceb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "Ton of smoke coming out of one of the new apartment buildings at 160 Ross in Auburn. Several fire trucks on scene. http://t.co/AHVYmSQHqC        \n",
      "\n",
      "Embedded version:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15, 128), dtype=float16, numpy=\n",
       "array([[[ 0.007362,  0.04126 ,  0.03842 , ..., -0.0191  , -0.0214  ,\n",
       "         -0.012726],\n",
       "        [ 0.00956 , -0.01265 ,  0.005924, ...,  0.0245  ,  0.002432,\n",
       "          0.03119 ],\n",
       "        [ 0.03017 ,  0.005383,  0.003016, ...,  0.0255  , -0.03778 ,\n",
       "          0.00862 ],\n",
       "        ...,\n",
       "        [-0.01794 , -0.0319  ,  0.04303 , ...,  0.001757, -0.009415,\n",
       "          0.01305 ],\n",
       "        [-0.03558 ,  0.000988,  0.007378, ...,  0.003181, -0.002184,\n",
       "          0.00644 ],\n",
       "        [-0.01396 , -0.006996, -0.03073 , ..., -0.014496,  0.009636,\n",
       "          0.01294 ]]], dtype=float16)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a random sentence from training set\n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(f\"Original text:\\n{random_sentence}\\\n",
    "        \\n\\nEmbedded version:\")\n",
    "\n",
    "# Embed the random sentence (turn it into numerical representation, aka tokenization first)\n",
    "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
    "sample_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QplJbX_3N9JH",
    "outputId": "10a44e5c-4de3-47ed-ba62-c55a057b7005"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(128,), dtype=float16, numpy=\n",
       "array([ 0.007362 ,  0.04126  ,  0.03842  ,  0.03287  ,  0.01956  ,\n",
       "       -0.03983  , -0.02554  , -0.04767  ,  0.02115  , -0.00438  ,\n",
       "        0.03925  ,  0.0178   , -0.04     , -0.00202  , -0.03864  ,\n",
       "        0.04886  , -0.04697  ,  0.02637  ,  0.013245 , -0.00333  ,\n",
       "       -0.00886  , -0.000745 ,  0.002062 , -0.03955  ,  0.036    ,\n",
       "        0.02502  ,  0.04416  ,  0.03964  , -0.02457  , -0.04102  ,\n",
       "        0.013466 ,  0.00173  ,  0.03903  ,  0.02805  , -0.04123  ,\n",
       "        0.000885 , -0.01622  , -0.001982 ,  0.02118  , -0.02927  ,\n",
       "        0.03976  , -0.04053  ,  0.00343  , -0.02342  ,  0.02293  ,\n",
       "       -0.01218  ,  0.02252  ,  0.013245 ,  0.0176   ,  0.00834  ,\n",
       "        0.01996  , -0.0226   ,  0.006214 , -0.02788  ,  0.03253  ,\n",
       "        0.04147  ,  0.01634  ,  0.01715  , -0.02531  , -0.01929  ,\n",
       "       -0.0353   , -0.04828  , -0.04898  ,  0.01974  , -0.01968  ,\n",
       "       -0.003256 , -0.02321  ,  0.02129  ,  0.04175  ,  0.002022 ,\n",
       "       -0.00859  ,  0.007442 ,  0.03616  ,  0.04074  ,  0.0203   ,\n",
       "       -0.01346  , -0.00424  , -0.03632  , -0.02194  ,  0.04977  ,\n",
       "       -0.0228   , -0.00989  , -0.03156  , -0.0335   , -0.002394 ,\n",
       "       -0.03165  , -0.0173   ,  0.02948  ,  0.02629  , -0.04697  ,\n",
       "        0.0151   , -0.048    , -0.004005 , -0.02861  ,  0.02878  ,\n",
       "       -0.0293   , -0.02592  , -0.0463   , -0.001058 ,  0.03152  ,\n",
       "       -0.02235  , -0.0258   , -0.002647 , -0.00287  ,  0.0003984,\n",
       "       -0.00815  ,  0.01991  , -0.03177  , -0.0415   ,  0.00538  ,\n",
       "        0.005848 , -0.001444 ,  0.001761 ,  0.04556  , -0.001121 ,\n",
       "        0.00587  , -0.02263  ,  0.03827  , -0.03366  ,  0.02625  ,\n",
       "       -0.04837  ,  0.03775  , -0.03946  ,  0.003439 ,  0.03442  ,\n",
       "       -0.0191   , -0.0214   , -0.012726 ], dtype=float16)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_embed[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UN7r1WeFOldx"
   },
   "source": [
    "## Modelling a text dataset (setting up our modelling experiments)\n",
    "\n",
    "Now we've got our data in numerical format, let's start building and comparing different models.\n",
    "\n",
    "* Model 0: Naive Bayes (baseline) - got this from here: https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html\n",
    "* Model 1: Feed-forward neural network (dense model)\n",
    "* Model 2: LSTM model\n",
    "* Model 3: GRU model\n",
    "* Model 4: Bidirectional LSTM\n",
    "* Model 5: 1D Convolutional Neural Network\n",
    "* Model 6: TensorFlow Hub Pretrained Word Embedding (feature extractor)\n",
    "* Model 7: Same as model 6 but using 10% of data\n",
    "\n",
    "For each of these models, we're going to be following the TensorFlow steps in modelling:\n",
    "* Construct the model\n",
    "* Train the model\n",
    "* Make predictions with the model\n",
    "* Track prediction evaluation metrics for later comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XEPVZ04JRrm1",
    "outputId": "05735c78-ebc5-44ed-a8c1-5307f09fc82a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 96.8 ms, sys: 3.55 ms, total: 100 ms\n",
      "Wall time: 99.9 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create tokenization and modelling pipeline\n",
    "model_0 = Pipeline([\n",
    "                    (\"tfidf\", TfidfVectorizer()), # convert words to numbers using tfidf - https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "                    (\"clf\", MultinomialNB()) # model the text converted to numbers\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "model_0.fit(train_sentences, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MEaWSAriT4tp",
    "outputId": "0604501f-70bb-4d43-f244-5040453f479b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our baseline model achieves an accuracy of: 79.27%\n"
     ]
    }
   ],
   "source": [
    "# Let's evalaute our baseline model\n",
    "baseline_score = model_0.score(val_sentences, val_labels)\n",
    "print(f\"Our baseline model achieves an accuracy of: {baseline_score*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dpnyMrKeT8G_",
    "outputId": "85c0331b-b82a-4b13-a36e-b6b46020cfb6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "baseline_preds = model_0.predict(val_sentences)\n",
    "baseline_preds[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "20W1OeuLUrYn"
   },
   "source": [
    "### Creating an evaluation function for our model experiments\n",
    "\n",
    "Let's make a function to evaluate our modelling experiment predictions using: \n",
    "* Accuracy\n",
    "* Precision\n",
    "* Recall\n",
    "* F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "E19vhmhtWsDz"
   },
   "outputs": [],
   "source": [
    "# Function to evalaute: accuracy, precision, recall, F1-score\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def calculate_results(y_true, y_pred):\n",
    "  \"\"\"\n",
    "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
    "\n",
    "  Args:\n",
    "  ----\n",
    "  y_true = true labels in the form of a 1D array\n",
    "  y_pred = predicted label in the form of a 1D array\n",
    "\n",
    "  Returns a dictionary of accuracy, precision, recall and f1-score between y_true and y_pred.\n",
    "  \"\"\"\n",
    "  # Calculate model accuracy\n",
    "  model_accuracy = accuracy_score(y_true, y_pred) * 100 # get accuracy score in percentage value\n",
    "  # Calculate model precision, recall and f1 score using \"weighted\" avergage\n",
    "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "  # Create a dictionary of model results\n",
    "  model_results = {\"accuracy\": model_accuracy,\n",
    "                   \"precision\": model_precision,\n",
    "                   \"recall\": model_recall,\n",
    "                   \"f1\": model_f1}\n",
    "  return model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uo42vAnvYNX4",
    "outputId": "c73a4556-5891-4bc6-bedd-6113817e8082"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 79.26509186351706,\n",
       " 'precision': 0.8111390004213173,\n",
       " 'recall': 0.7926509186351706,\n",
       " 'f1': 0.7862189758049549}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get baseline results\n",
    "baseline_results = calculate_results(y_true=val_labels,\n",
    "                                     y_pred=baseline_preds)\n",
    "baseline_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IT_MFZjLYUEN"
   },
   "source": [
    "### Model 1: A simple dense model (feed-forward neural network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "dSC_uEPjZSX-"
   },
   "outputs": [],
   "source": [
    "# Create tensorboard callback (need to create a new one for each model)\n",
    "from helper_functions import create_tensorboard_callback\n",
    "\n",
    "# Create directory to save TensorBoard logs\n",
    "SAVE_DIR = \"model_logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xu2-xPY_Z_3I",
    "outputId": "03545174-5022-4847-c5dc-9087c347ccf6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
       "       'Imagine getting flattened by Kurt Zouma',\n",
       "       '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
       "       \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
       "       'Somehow find you and I collide http://t.co/Ee8RpOahPk'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "id": "53o_tpRMZhXG"
   },
   "outputs": [],
   "source": [
    "# Build model with the Functional API\n",
    "from tensorflow.keras import layers\n",
    "inputs = layers.Input(shape=(1,), dtype=tf.string) # inputs are 1-dimensional strings\n",
    "x = text_vectorizer(inputs) # turn the input text into numbers \n",
    "x = embedding(x)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\") # construct the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1_dense\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " global_average_pooling1d_4   (None, 128)              0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 4)                 516       \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,280,521\n",
      "Trainable params: 1,280,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1K5tE6dia6Ls",
    "outputId": "3caa5739-91fd-434d-e29c-76290260e523"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_1_dense/20220507-182425\n",
      "Epoch 1/15\n",
      "215/215 [==============================] - 1s 4ms/step - loss: 0.3830 - accuracy: 0.9453 - val_loss: 0.4937 - val_accuracy: 0.7690\n",
      "Epoch 2/15\n",
      "215/215 [==============================] - 1s 4ms/step - loss: 0.1771 - accuracy: 0.9729 - val_loss: 0.5211 - val_accuracy: 0.7690\n",
      "Epoch 3/15\n",
      "215/215 [==============================] - 1s 4ms/step - loss: 0.1208 - accuracy: 0.9797 - val_loss: 0.5685 - val_accuracy: 0.7690\n",
      "Epoch 4/15\n",
      "215/215 [==============================] - 1s 4ms/step - loss: 0.0943 - accuracy: 0.9809 - val_loss: 0.6156 - val_accuracy: 0.7690\n",
      "Epoch 5/15\n",
      "215/215 [==============================] - 1s 4ms/step - loss: 0.0792 - accuracy: 0.9820 - val_loss: 0.6596 - val_accuracy: 0.7703\n",
      "Epoch 6/15\n",
      "215/215 [==============================] - 1s 4ms/step - loss: 0.0695 - accuracy: 0.9812 - val_loss: 0.7038 - val_accuracy: 0.7690\n",
      "Epoch 7/15\n",
      "215/215 [==============================] - 1s 4ms/step - loss: 0.0628 - accuracy: 0.9823 - val_loss: 0.7427 - val_accuracy: 0.7625\n",
      "Epoch 8/15\n",
      "215/215 [==============================] - 1s 4ms/step - loss: 0.0578 - accuracy: 0.9819 - val_loss: 0.7817 - val_accuracy: 0.7638\n",
      "Epoch 9/15\n",
      "215/215 [==============================] - 1s 4ms/step - loss: 0.0537 - accuracy: 0.9823 - val_loss: 0.8200 - val_accuracy: 0.7598\n",
      "Epoch 10/15\n",
      "215/215 [==============================] - 1s 4ms/step - loss: 0.0508 - accuracy: 0.9819 - val_loss: 0.8586 - val_accuracy: 0.7612\n",
      "Epoch 11/15\n",
      "215/215 [==============================] - 1s 4ms/step - loss: 0.0483 - accuracy: 0.9832 - val_loss: 0.8917 - val_accuracy: 0.7638\n",
      "Epoch 12/15\n",
      "215/215 [==============================] - 1s 4ms/step - loss: 0.0466 - accuracy: 0.9825 - val_loss: 0.9308 - val_accuracy: 0.7638\n",
      "Epoch 13/15\n",
      "215/215 [==============================] - 1s 4ms/step - loss: 0.0450 - accuracy: 0.9828 - val_loss: 0.9619 - val_accuracy: 0.7625\n",
      "Epoch 14/15\n",
      "215/215 [==============================] - 1s 4ms/step - loss: 0.0436 - accuracy: 0.9825 - val_loss: 0.9947 - val_accuracy: 0.7585\n",
      "Epoch 15/15\n",
      "215/215 [==============================] - 1s 4ms/step - loss: 0.0423 - accuracy: 0.9823 - val_loss: 1.0239 - val_accuracy: 0.7598\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "model_1.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "history_1 = model_1.fit(train_sentences,\n",
    "                        train_labels, \n",
    "                        epochs=15,\n",
    "                        validation_data=(val_sentences, val_labels),\n",
    "                        callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
    "                                                               experiment_name=\"model_1_dense\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TJr9cNmEbjf-",
    "outputId": "b127120e-af5e-4599-f2aa-a83d73617bbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.7782\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4814818501472473, 0.778215229511261]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate model 1\n",
    "model_1.evaluate(val_sentences, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IXoHTxElcp88",
    "outputId": "235f43d4-622b-4d9b-f2fd-d92518f41499"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.348  ],\n",
       "       [0.715  ],\n",
       "       [0.998  ],\n",
       "       [0.1619 ],\n",
       "       [0.10614],\n",
       "       [0.945  ],\n",
       "       [0.9136 ],\n",
       "       [0.993  ],\n",
       "       [0.966  ],\n",
       "       [0.3457 ]], dtype=float16)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with model_1\n",
    "model_1_pred_probs = model_1.predict(val_sentences)\n",
    "model_1_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "le7bc1SWc2Ga",
    "outputId": "40f29b5f-76aa-4396-d0d9-bf9fdc9a768e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float16, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float16)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert model_1 pred probs from probabilities to prediction labels\n",
    "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs))\n",
    "model_1_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cAwelDTHdCqb",
    "outputId": "84cca678-7a9b-4536-c64f-6e3c1c54d2cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1, 1, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZEk3d_4Rcbs-",
    "outputId": "c7a31267-4761-4541-ebe1-ee803304e23e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.82152230971128,\n",
       " 'precision': 0.7814103276314137,\n",
       " 'recall': 0.7782152230971129,\n",
       " 'f1': 0.7756075024838144}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate model_1 with our evaluation function\n",
    "model_1_results = calculate_results(y_true=val_labels,\n",
    "                                    y_pred=model_1_preds)\n",
    "model_1_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eG6GQuq0d3MH",
    "outputId": "a160607d-c165-414a-ecc7-20efd3155415"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 79.26509186351706,\n",
       " 'precision': 0.8111390004213173,\n",
       " 'recall': 0.7926509186351706,\n",
       " 'f1': 0.7862189758049549}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y4_Erx95azN5",
    "outputId": "6520aef1-956d-477c-d693-7107df6b1109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(list(model_1_results.values())) > np.array(list(baseline_results.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rJ51vV3qdzDF"
   },
   "source": [
    "### Visualizing learned embeddings\n",
    "\n",
    "To further understand word embeddings, let's visualize them, to do so, we'll get the weights matrix (embedding matrix) from our embedding layer and visualize it using the Embedding project tool, see the TensorFlow guide for more: https://www.tensorflow.org/tutorials/text/word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-JEsoRe2mgY2",
    "outputId": "24fac085-10d1-405c-dd21-f5d29d7674b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is'])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the vocabulary from the text vectorization layer\n",
    "words_in_vocab = text_vectorizer.get_vocabulary()\n",
    "len(words_in_vocab), words_in_vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gWj7h27bmrKN",
    "outputId": "0d4c369a-ee81-4e50-c00a-6901bb434e63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1_dense\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 128)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,280,129\n",
      "Trainable params: 1,280,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "elGf0lzDmxhG",
    "outputId": "133c39ed-5ffa-40d4-e523-8c11488b9b13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 128)\n"
     ]
    }
   ],
   "source": [
    "# Get the weight matrix of embedding layer\n",
    "# (the weights are the numerical patterns between the text in the training dataset that the model has learned)\n",
    "embed_weights = model_1.get_layer(\"embedding\").get_weights()[0]\n",
    "print(embed_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "sQosT7XxnLOA"
   },
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "# Code to save trained embeddings to file - we got this from here: https://www.tensorflow.org/tutorials/text/word_embeddings#retrieve_the_trained_word_embeddings_and_save_them_to_disk\n",
    "out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
    "out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "for index, word in enumerate(words_in_vocab):\n",
    "  if index == 0:\n",
    "    continue  # skip 0, it's padding.\n",
    "  vec = embed_weights[index]\n",
    "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
    "  out_m.write(word + \"\\n\")\n",
    "out_v.close()\n",
    "out_m.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "xhLv8IRApRrh",
    "outputId": "92c3fdbc-5baa-4655-8140-a8daf7229b6b"
   },
   "outputs": [],
   "source": [
    "# # Let's download the saved embeddings locally\n",
    "# try:\n",
    "#   from google.colab import files\n",
    "#   files.download('vectors.tsv')\n",
    "#   files.download('metadata.tsv')\n",
    "# except Exception:\n",
    "#   pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tb0CFUDlqm9w"
   },
   "source": [
    "Our visual word embeddings might not look like much to us, but they help our model understand the relationships between words.\n",
    "\n",
    "For more on a popular type of word embedding and more visual explanations check out the illustrated word2vec: https://jalammar.github.io/illustrated-word2vec/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GIGssmQIpqTr"
   },
   "source": [
    "## Model 2: LSTM\n",
    "\n",
    "* LSTM = long short-term memory\n",
    "\n",
    "For more on RNN's/resources to learn, see here: https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/08_introduction_to_nlp_in_tensorflow.ipynb \n",
    "\n",
    "We're going to focus on writing the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WoEAithmrUjh",
    "outputId": "eb4339fb-9bc5-44e2-e53c-3968c82efa5f"
   },
   "outputs": [],
   "source": [
    "# Create LSTM model\n",
    "from tensorflow.keras import layers\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "# print(f\"After embedding: {x.shape}\")\n",
    "# x = layers.LSTM(64, activation=\"tanh\", return_sequences=True)(x)# use return_sequences=True if you want to stack recurrent layers \n",
    "# # print(f\"After LSTM cell with return_sequences=True: {x.shape}\")\n",
    "x = layers.LSTM(64, activation=\"tanh\")(x)\n",
    "# print(f\"After LSTM cell: {x.shape}\")\n",
    "# x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer to have on top of LSTM layer\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "COCCOInqtm3r",
    "outputId": "3be56ba5-4f4d-4926-d9b2-8c07535144c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_2_LSTM/20220507-181254\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-07 18:12:56.165958: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215/215 [==============================] - 3s 7ms/step - loss: 0.2275 - accuracy: 0.9193 - val_loss: 0.5207 - val_accuracy: 0.7795\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 1s 6ms/step - loss: 0.1576 - accuracy: 0.9412 - val_loss: 0.6405 - val_accuracy: 0.7808\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 1s 6ms/step - loss: 0.1298 - accuracy: 0.9512 - val_loss: 0.6734 - val_accuracy: 0.7874\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 1s 6ms/step - loss: 0.1063 - accuracy: 0.9606 - val_loss: 0.8297 - val_accuracy: 0.7835\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 1s 6ms/step - loss: 0.0815 - accuracy: 0.9675 - val_loss: 0.9988 - val_accuracy: 0.7717\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "model_2.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit model\n",
    "history_2 = model_2.fit(train_sentences,\n",
    "                        train_labels,\n",
    "                        epochs=5,\n",
    "                        validation_data=(val_sentences, val_labels),\n",
    "                        callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
    "                                                               experiment_name=\"model_2_LSTM\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O0jw2e3Dukbz",
    "outputId": "f1a4975c-14f5-454d-8f19-7fe1da95ce4e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((762, 1),\n",
       " array([[5.234e-02],\n",
       "        [7.764e-01],\n",
       "        [1.000e+00],\n",
       "        [1.349e-01],\n",
       "        [3.393e-04],\n",
       "        [1.000e+00],\n",
       "        [9.194e-01],\n",
       "        [1.000e+00],\n",
       "        [1.000e+00],\n",
       "        [5.049e-01]], dtype=float16))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions on the validation dataset\n",
    "model_2_pred_probs = model_2.predict(val_sentences)\n",
    "model_2_pred_probs.shape, model_2_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vQFF0dbQu76A",
    "outputId": "21c01f99-2b32-4202-a1d2-2d14f241d25c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float16, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float16)>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Round out pred probs and reduce to 1-dimensional array\n",
    "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
    "model_2_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "23g9TGPFu_2E",
    "outputId": "dec57c07-3986-44f3-dc84-0a10c495ca76"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float16, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float16)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate our LSTM model's results\n",
    "model_2_preds = tf.squeeze(tf.round(model_2_preds))\n",
    "model_2_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ANaN1vIkvRUI",
    "outputId": "b88165ed-a60f-4763-d72c-8ca2af8e9bce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.16535433070865,\n",
       " 'precision': 0.7712961349150494,\n",
       " 'recall': 0.7716535433070866,\n",
       " 'f1': 0.7711315357952713}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate our model 2 results\n",
    "model_2_results = calculate_results(y_true=val_labels,\n",
    "                                    y_pred=model_2_preds)\n",
    "model_2_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eyZecZmtvYfS"
   },
   "source": [
    "## Model 3: GRU\n",
    "\n",
    "GRU = Gated recurrent unit (one of the most popular and useful recurrent layer types)\n",
    "\n",
    "üìñ **Resource:** If you want to see the formula for Tanh, a great extension would be to replicate the function in pure TensorFlow, see here: https://ml-cheatsheet.readthedocs.io/en/latest/activation_functions.html#tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "XpHDZdF6TqmN"
   },
   "outputs": [],
   "source": [
    "# Build an RNN using the GRU cell\n",
    "from tensorflow.keras import layers\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "# x = layers.GRU(64, activation=\"tanh\", return_sequences=True)(x) # return_sequences=True is required for stacking recurrent cells\n",
    "# print(x.shape)\n",
    "x = layers.GRU(64, activation=\"tanh\")(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G5m4ts3vUhDs",
    "outputId": "0521fcb9-d8ce-434b-cc2c-0f62b91e227e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3_GRU\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 64)                37248     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,317,313\n",
      "Trainable params: 1,317,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get a summary\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VBert-9mVK-3",
    "outputId": "1c0313dd-6d8d-4237-d0f9-30bcd2683e2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_3_GRU/20220507-181303\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 3s 6ms/step - loss: 0.6536 - accuracy: 0.6453 - val_loss: 0.6599 - val_accuracy: 0.6129\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 1s 5ms/step - loss: 0.6044 - accuracy: 0.6939 - val_loss: 0.6334 - val_accuracy: 0.6417\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 1s 5ms/step - loss: 0.5400 - accuracy: 0.7526 - val_loss: 0.5899 - val_accuracy: 0.6785\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 1s 5ms/step - loss: 0.3851 - accuracy: 0.8583 - val_loss: 0.5002 - val_accuracy: 0.7756\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 1s 5ms/step - loss: 0.1303 - accuracy: 0.9692 - val_loss: 0.6314 - val_accuracy: 0.7835\n"
     ]
    }
   ],
   "source": [
    "# Compile model_3 (GRU)\n",
    "model_3.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.SGD(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit model\n",
    "model_3_history = model_3.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
    "                                                                     experiment_name=\"model_3_GRU\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hOpajuC1VsoA",
    "outputId": "6604997a-6172-4dc3-9491-b889a5f69cdb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.3782 ],\n",
       "        [0.4807 ],\n",
       "        [0.997  ],\n",
       "        [0.0397 ],\n",
       "        [0.00368],\n",
       "        [0.954  ],\n",
       "        [0.838  ],\n",
       "        [0.998  ],\n",
       "        [0.995  ],\n",
       "        [0.527  ]], dtype=float16),\n",
       " (762, 1))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with the trained model\n",
    "model_3_pred_probs = model_3.predict(val_sentences)\n",
    "model_3_pred_probs[:10], model_3_pred_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gWOxXpgbV8gn",
    "outputId": "7f8b4d4e-f1b6-4378-f594-cf984aa81a26"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float16, numpy=array([0., 0., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float16)>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert model 3 pred probs into labels\n",
    "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
    "model_3_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rxJc3qxCWKFk",
    "outputId": "f1fd6b88-acb1-4b89-ad8f-e5bf1d6921c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 78.34645669291339,\n",
       " 'precision': 0.7850204173056048,\n",
       " 'recall': 0.7834645669291339,\n",
       " 'f1': 0.7816801653861306}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate results for model 3\n",
    "model_3_results = calculate_results(y_true=val_labels,\n",
    "                                    y_pred=model_3_preds)\n",
    "model_3_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SmE3Nfc9WLZE"
   },
   "source": [
    "## Model 4: Bidirectional RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "yIEUGLncW9_n"
   },
   "outputs": [],
   "source": [
    "# Build a bidirectional RNN in TensorFlow\n",
    "from tensorflow.keras import layers\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "#x = layers.Bidirectional(layers.GRU(64, return_sequences=True))(x) # return_sequences=True required for stacking RNN layers\n",
    "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_4 = tf.keras.Model(inputs, outputs, name=\"model_4_bidirectional\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k24AosTtYoqT",
    "outputId": "2c2d8b7e-8c68-4583-af03-77446e171cf2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4_bidirectional\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 128)              98816     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,395,457\n",
      "Trainable params: 1,395,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DJTex7vKYuSH",
    "outputId": "2cf6ef8a-34b6-40c3-c5d2-13f8141bd44f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_4_bidirectional/20220507-181311\n",
      "Epoch 1/15\n",
      "215/215 [==============================] - 4s 9ms/step - loss: 0.6167 - accuracy: 0.8053 - val_loss: 0.6077 - val_accuracy: 0.7270\n",
      "Epoch 2/15\n",
      "215/215 [==============================] - 1s 7ms/step - loss: 0.4384 - accuracy: 0.9029 - val_loss: 0.5039 - val_accuracy: 0.7769\n",
      "Epoch 3/15\n",
      "215/215 [==============================] - 1s 7ms/step - loss: 0.2288 - accuracy: 0.9645 - val_loss: 0.4954 - val_accuracy: 0.7835\n",
      "Epoch 4/15\n",
      "215/215 [==============================] - 1s 7ms/step - loss: 0.1288 - accuracy: 0.9707 - val_loss: 0.5638 - val_accuracy: 0.7808\n",
      "Epoch 5/15\n",
      "215/215 [==============================] - 1s 7ms/step - loss: 0.1016 - accuracy: 0.9698 - val_loss: 0.6162 - val_accuracy: 0.7782\n",
      "Epoch 6/15\n",
      "215/215 [==============================] - 1s 7ms/step - loss: 0.0914 - accuracy: 0.9708 - val_loss: 0.6500 - val_accuracy: 0.7782\n",
      "Epoch 7/15\n",
      "215/215 [==============================] - 1s 7ms/step - loss: 0.0854 - accuracy: 0.9721 - val_loss: 0.6760 - val_accuracy: 0.7743\n",
      "Epoch 8/15\n",
      "215/215 [==============================] - 1s 7ms/step - loss: 0.0807 - accuracy: 0.9729 - val_loss: 0.7000 - val_accuracy: 0.7730\n",
      "Epoch 9/15\n",
      "215/215 [==============================] - 1s 7ms/step - loss: 0.0776 - accuracy: 0.9733 - val_loss: 0.7212 - val_accuracy: 0.7743\n",
      "Epoch 10/15\n",
      "215/215 [==============================] - 1s 7ms/step - loss: 0.0761 - accuracy: 0.9729 - val_loss: 0.7369 - val_accuracy: 0.7743\n",
      "Epoch 11/15\n",
      "215/215 [==============================] - 1s 7ms/step - loss: 0.0735 - accuracy: 0.9740 - val_loss: 0.7544 - val_accuracy: 0.7769\n",
      "Epoch 12/15\n",
      "215/215 [==============================] - 1s 7ms/step - loss: 0.0728 - accuracy: 0.9742 - val_loss: 0.7820 - val_accuracy: 0.7808\n",
      "Epoch 13/15\n",
      "215/215 [==============================] - 1s 7ms/step - loss: 0.0713 - accuracy: 0.9749 - val_loss: 0.7808 - val_accuracy: 0.7769\n",
      "Epoch 14/15\n",
      "215/215 [==============================] - 1s 7ms/step - loss: 0.0700 - accuracy: 0.9737 - val_loss: 0.7992 - val_accuracy: 0.7808\n",
      "Epoch 15/15\n",
      "215/215 [==============================] - 1s 7ms/step - loss: 0.0693 - accuracy: 0.9746 - val_loss: 0.8111 - val_accuracy: 0.7782\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "model_4.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.SGD(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit model\n",
    "history_model_4 = model_4.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=15,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
    "                                                                     experiment_name=\"model_4_bidirectional\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6uf4_4y1aMYv",
    "outputId": "1b718d32-1f1d-43e6-8790-9482a5c03d2e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.892e-01],\n",
       "        [7.495e-01],\n",
       "        [9.990e-01],\n",
       "        [1.342e-02],\n",
       "        [9.966e-04],\n",
       "        [9.951e-01],\n",
       "        [9.341e-01],\n",
       "        [9.990e-01],\n",
       "        [9.990e-01],\n",
       "        [5.469e-01]], dtype=float16),\n",
       " (762, 1))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with our bidirectional model\n",
    "model_4_pred_probs = model_4.predict(val_sentences)\n",
    "model_4_pred_probs[:10], model_4_pred_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Q7Kh777aiNF",
    "outputId": "337e4c87-4e95-410f-d696-1b1f4a3819f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float16, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float16)>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert pred probs to labels\n",
    "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n",
    "model_4_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g8wNtN5sarja",
    "outputId": "8d36d2aa-244e-43fc-cbb0-567b34b946fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.82152230971128,\n",
       " 'precision': 0.7791991586469295,\n",
       " 'recall': 0.7782152230971129,\n",
       " 'f1': 0.7766208088282468}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model 4 results\n",
    "model_4_results = calculate_results(y_true=val_labels,\n",
    "                                    y_pred=model_4_preds)\n",
    "model_4_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4k4a1F7oatvK"
   },
   "source": [
    "## Model 5: Conv1D\n",
    "\n",
    "We've seen before how convolutional neural networks can be used for images but they can also be used for text.\n",
    "\n",
    "Previously we've used the layer Conv2D (which is great for images with (height, width)).\n",
    "\n",
    "But if we want to use convolutional layers for sequences (e.g. text) we need to use Conv1D: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv1D\n",
    "\n",
    "For more of a deep dive into what goes on behind the scenes in a CNN for text (or sequences) see the paper: https://arxiv.org/abs/1809.08037"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-ti4uulyc8s6",
    "outputId": "8f9fa0df-b2d4-4662-8600-2abcb76e7f96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding output shape: (1, 15, 128)\n",
      "Conv1D output shape: (1, 13, 32)\n",
      "Max pool output shape: (1, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-07 18:13:37.949073: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# Let's do a little test to see what things look like through the eyes of a Conv1D layer\n",
    "embedding_test = embedding(text_vectorizer([\"this is a test sentence\"])) # turn target sentence into embedding\n",
    "conv_1d_layer = layers.Conv1D(filters=32,\n",
    "                              kernel_size=3, # setting this to 5 means it'll look at 5 words at a time, 3 would mean 3 words at a time\n",
    "                              activation=\"relu\")\n",
    "conv_1d_output = conv_1d_layer(embedding_test)\n",
    "max_pool = layers.GlobalMaxPool1D()\n",
    "max_pool_output = max_pool(conv_1d_output)\n",
    "print(f\"Embedding output shape: {embedding_test.shape}\")\n",
    "print(f\"Conv1D output shape: {conv_1d_output.shape}\")\n",
    "print(f\"Max pool output shape: {max_pool_output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LzhUsJ5Te2qG",
    "outputId": "7d19e15c-65f4-47db-df93-bf95b583fa3c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding output: [[[-0.01576   0.0195    0.003513 ... -0.02248   0.02286   0.03308 ]\n",
      "  [ 0.03818  -0.00855   0.0065   ... -0.05432  -0.0967   -0.0201  ]\n",
      "  [ 0.0207   -0.006744  0.002672 ...  0.001518  0.03757  -0.05225 ]\n",
      "  ...\n",
      "  [-0.03091   0.02078   0.01259  ...  0.003305 -0.02429  -0.002474]\n",
      "  [-0.03091   0.02078   0.01259  ...  0.003305 -0.02429  -0.002474]\n",
      "  [-0.03091   0.02078   0.01259  ...  0.003305 -0.02429  -0.002474]]]\n",
      "Conv1D output: [[[0.01145  0.       0.002604 0.0914   0.009514 0.       0.\n",
      "   0.       0.       0.02977  0.0031   0.002016 0.       0.04013\n",
      "   0.01988  0.02939  0.06793  0.       0.       0.       0.\n",
      "   0.       0.0907   0.       0.02895  0.       0.006496 0.03485\n",
      "   0.0319   0.0088   0.01572  0.      ]\n",
      "  [0.       0.       0.       0.0229   0.       0.1212   0.\n",
      "   0.       0.       0.0408   0.       0.0999   0.002428 0.\n",
      "   0.02498  0.0343   0.03026  0.01505  0.       0.       0.005157\n",
      "   0.       0.011406 0.00982  0.02008  0.       0.04507  0.\n",
      "   0.02588  0.       0.       0.05127 ]\n",
      "  [0.       0.       0.02824  0.       0.01779  0.       0.\n",
      "   0.       0.04938  0.       0.       0.006836 0.       0.\n",
      "   0.       0.       0.000422 0.0633   0.001883 0.       0.\n",
      "   0.0825   0.       0.04922  0.06006  0.06537  0.04718  0.1071\n",
      "   0.05948  0.00641  0.04764  0.      ]\n",
      "  [0.       0.       0.       0.005676 0.       0.11365  0.\n",
      "   0.0328   0.013374 0.05212  0.06046  0.007626 0.04404  0.05847\n",
      "   0.06726  0.       0.       0.       0.       0.1044   0.03793\n",
      "   0.0487   0.0861   0.       0.011536 0.1063   0.00698  0.\n",
      "   0.005047 0.       0.0116   0.01947 ]\n",
      "  [0.       0.0336   0.       0.       0.03693  0.00863  0.\n",
      "   0.       0.10016  0.01228  0.02083  0.0774   0.03004  0.0501\n",
      "   0.05347  0.01657  0.01653  0.       0.       0.03754  0.03864\n",
      "   0.002176 0.       0.05182  0.01384  0.0998   0.       0.\n",
      "   0.       0.       0.       0.03735 ]\n",
      "  [0.       0.       0.01098  0.       0.01872  0.       0.\n",
      "   0.       0.0858   0.02121  0.       0.05655  0.01397  0.04776\n",
      "   0.0752   0.       0.006874 0.04153  0.       0.0421   0.03943\n",
      "   0.       0.03415  0.       0.03513  0.05524  0.       0.\n",
      "   0.       0.       0.       0.05804 ]\n",
      "  [0.       0.       0.01098  0.       0.01872  0.       0.\n",
      "   0.       0.0858   0.02121  0.       0.05655  0.01397  0.04776\n",
      "   0.0752   0.       0.006874 0.04153  0.       0.0421   0.03943\n",
      "   0.       0.03415  0.       0.03513  0.05524  0.       0.\n",
      "   0.       0.       0.       0.05804 ]\n",
      "  [0.       0.       0.01098  0.       0.01872  0.       0.\n",
      "   0.       0.0858   0.02121  0.       0.05655  0.01397  0.04776\n",
      "   0.0752   0.       0.006874 0.04153  0.       0.0421   0.03943\n",
      "   0.       0.03415  0.       0.03513  0.05524  0.       0.\n",
      "   0.       0.       0.       0.05804 ]\n",
      "  [0.       0.       0.01098  0.       0.01872  0.       0.\n",
      "   0.       0.0858   0.02121  0.       0.05655  0.01397  0.04776\n",
      "   0.0752   0.       0.006874 0.04153  0.       0.0421   0.03943\n",
      "   0.       0.03415  0.       0.03513  0.05524  0.       0.\n",
      "   0.       0.       0.       0.05804 ]\n",
      "  [0.       0.       0.01098  0.       0.01872  0.       0.\n",
      "   0.       0.0858   0.02121  0.       0.05655  0.01397  0.04776\n",
      "   0.0752   0.       0.006874 0.04153  0.       0.0421   0.03943\n",
      "   0.       0.03415  0.       0.03513  0.05524  0.       0.\n",
      "   0.       0.       0.       0.05804 ]\n",
      "  [0.       0.       0.01098  0.       0.01872  0.       0.\n",
      "   0.       0.0858   0.02121  0.       0.05655  0.01397  0.04776\n",
      "   0.0752   0.       0.006874 0.04153  0.       0.0421   0.03943\n",
      "   0.       0.03415  0.       0.03513  0.05524  0.       0.\n",
      "   0.       0.       0.       0.05804 ]\n",
      "  [0.       0.       0.01098  0.       0.01872  0.       0.\n",
      "   0.       0.0858   0.02121  0.       0.05655  0.01397  0.04776\n",
      "   0.0752   0.       0.006874 0.04153  0.       0.0421   0.03943\n",
      "   0.       0.03415  0.       0.03513  0.05524  0.       0.\n",
      "   0.       0.       0.       0.05804 ]\n",
      "  [0.       0.       0.01098  0.       0.01872  0.       0.\n",
      "   0.       0.0858   0.02121  0.       0.05655  0.01397  0.04776\n",
      "   0.0752   0.       0.006874 0.04153  0.       0.0421   0.03943\n",
      "   0.       0.03415  0.       0.03513  0.05524  0.       0.\n",
      "   0.       0.       0.       0.05804 ]]]\n",
      "Max pool output: [[0.01145  0.0336   0.02824  0.0914   0.03693  0.1212   0.       0.0328\n",
      "  0.10016  0.05212  0.06046  0.0999   0.04404  0.05847  0.0752   0.0343\n",
      "  0.06793  0.0633   0.001883 0.1044   0.03943  0.0825   0.0907   0.05182\n",
      "  0.06006  0.1063   0.04718  0.1071   0.05948  0.0088   0.04764  0.05804 ]]\n"
     ]
    }
   ],
   "source": [
    "# Let's see the outputs of each layer\n",
    "print(f\"Embedding output: {embedding_test}\")\n",
    "print(f\"Conv1D output: {conv_1d_output}\")\n",
    "print(f\"Max pool output: {max_pool_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bh0b92eqfpCY",
    "outputId": "8bd81d40-eda2-4644-afce-61a6ce1f36e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5_conv1d\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 11, 32)            20512     \n",
      "                                                                 \n",
      " global_max_pooling1d_1 (Glo  (None, 32)               0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,300,545\n",
      "Trainable params: 1,300,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create 1-dimensional CNN to model sequences\n",
    "from tensorflow.keras import layers\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "x = layers.Conv1D(filters=32, kernel_size=5, activation=\"relu\")(x)\n",
    "x = layers.GlobalMaxPool1D()(x)\n",
    "# x = layers.Dense(64, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\", name=\"output_layer\")(x)\n",
    "model_5 = tf.keras.Model(inputs, outputs, name=\"model_5_conv1d\")\n",
    "\n",
    "model_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "k41K63I4iVz0"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-sTeVF7thxRA",
    "outputId": "af18d3ef-2e6d-4523-bab1-1d425a53dde3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_5_conv1d/20220507-181338\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 2s 5ms/step - loss: 0.1619 - accuracy: 0.9442 - val_loss: 0.7469 - val_accuracy: 0.7795\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 1s 5ms/step - loss: 0.1024 - accuracy: 0.9628 - val_loss: 0.8456 - val_accuracy: 0.7756\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 1s 5ms/step - loss: 0.0798 - accuracy: 0.9692 - val_loss: 0.9735 - val_accuracy: 0.7677\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 1s 4ms/step - loss: 0.0686 - accuracy: 0.9749 - val_loss: 0.9998 - val_accuracy: 0.7717\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 1s 5ms/step - loss: 0.0605 - accuracy: 0.9765 - val_loss: 1.0922 - val_accuracy: 0.7703\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "model_5.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "history_model_5 = model_5.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
    "                                                                     experiment_name=\"model_5_conv1d\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3sCcYEWNjYi5",
    "outputId": "b8622a66-43d2-46f5-f834-ef0c084c979a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.4077],\n",
       "        [0.582 ],\n",
       "        [1.    ],\n",
       "        [0.0359],\n",
       "        [0.    ]], dtype=float16),\n",
       " (762, 1))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with our 1D CNN\n",
    "model_5_pred_probs = model_5.predict(val_sentences)\n",
    "model_5_pred_probs[:5], model_5_pred_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XxJsKzVWjqhX",
    "outputId": "97570fd5-826e-44f0-ae33-efdfca315f9a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float16, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float16)>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert model 5 pred probs to labels\n",
    "model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))\n",
    "model_5_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dOWYkGlZjqLK",
    "outputId": "bca5747f-5804-4ac3-a71f-0b9bc792c473"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.03412073490814,\n",
       " 'precision': 0.7720778836459699,\n",
       " 'recall': 0.7703412073490814,\n",
       " 'f1': 0.7681933440908485}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate results for model 5\n",
    "model_5_results = calculate_results(y_true=val_labels,\n",
    "                                    y_pred=model_5_preds)\n",
    "model_5_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kM3n8i-mj7hH"
   },
   "source": [
    "## Model 6: TensorFlow Hub Pretrained Sentence Encoder\n",
    "\n",
    "Now we've built a few of our own models, let's try and use transfer learning for NLP, specifically using TensorFlow Hub's Universal Sentence Encoder: https://tfhub.dev/google/universal-sentence-encoder/4\n",
    "\n",
    "See how the USE was created here: https://arxiv.org/abs/1803.11175\n",
    "\n",
    "üìñ **Resource:** TensorFlow Hub is a great resource for many pretrained models but HuggingFace is also another incredible resource for many pretrained NLP models (using HuggingFace model is beyond the scope of this course but it is definitely something you should be familiar with in the NLP space): https://huggingface.co/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "3K8Vuw-uG_ZJ",
    "outputId": "e553a614-d258-435b-94c7-5e9e8b9175f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"There's a flood in my street!\""
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sdQhymwZD3Rp",
    "outputId": "2e1e387b-267b-4373-fb85-3cc6575cc038"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[-0.01157027  0.0248591   0.02878048 -0.012715    0.03971538  0.0882776\n",
      "  0.02680985  0.05589838 -0.01068729 -0.00597292  0.00639323 -0.0181952\n",
      "  0.00030814  0.09105888  0.05874645 -0.03180628  0.01512474 -0.05162929\n",
      "  0.00991367 -0.06865346 -0.04209305  0.0267898   0.03011008  0.00321069\n",
      " -0.00337971 -0.04787356  0.02266719 -0.00985925 -0.04063613 -0.01292093\n",
      " -0.04666384  0.056303   -0.03949255  0.00517688  0.02495828 -0.07014441\n",
      "  0.02871508  0.04947684 -0.00633978 -0.08960193  0.02807117 -0.00808362\n",
      " -0.01360601  0.0599865  -0.10361787 -0.05195374  0.00232955 -0.0233253\n",
      " -0.03758105  0.03327729], shape=(50,), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-07 18:13:47.983048: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "embed_samples = embed([sample_sentence,\n",
    "                       \"When you can the universal sentence encoder on a sentence, it turns it into numbers.\"])\n",
    "print(embed_samples[0][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BFH2uFBcGzH8",
    "outputId": "fc4769e3-da05-4cea-ce78-2e4f8813b1ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([512])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_samples[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "mZOcXMLiG-U2"
   },
   "outputs": [],
   "source": [
    "# Create a Keras Layer using the USE pretrained layer from tensorflow hub\n",
    "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
    "                                        input_shape=[],\n",
    "                                        dtype=tf.string,\n",
    "                                        trainable=False,\n",
    "                                        name=\"USE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DONRMBLXJcAa",
    "outputId": "8b810e73-8144-4149-f5a3-d6a2ae9c71dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6_USE\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " USE (KerasLayer)            (None, 512)               256797824 \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                32832     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 4)                 36        \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256,833,441\n",
      "Trainable params: 35,617\n",
      "Non-trainable params: 256,797,824\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create model using the Sequential API\n",
    "model_6 = tf.keras.Sequential([\n",
    "  sentence_encoder_layer,\n",
    "  layers.Dense(64, activation=\"relu\"),\n",
    "  layers.Dense(32, activation=\"relu\"),\n",
    "  layers.Dense(16, activation=\"relu\"),\n",
    "  layers.Dense(8, activation=\"relu\"),\n",
    "  layers.Dense(4, activation=\"relu\"),\n",
    "  layers.Dense(1, activation=\"sigmoid\", name=\"output_layer\")                               \n",
    "], name=\"model_6_USE\")\n",
    "\n",
    "# Compile\n",
    "model_6.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=.0001),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "model_6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7uALDPUuJ3Cx",
    "outputId": "a6dc8bd8-8576-464c-bc31-9a71b4d95350",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder/20220507-181351\n",
      "Epoch 1/15\n",
      "215/215 [==============================] - 5s 13ms/step - loss: 0.6829 - accuracy: 0.5932 - val_loss: 0.6618 - val_accuracy: 0.6601\n",
      "Epoch 2/15\n",
      "215/215 [==============================] - 2s 11ms/step - loss: 0.6053 - accuracy: 0.7495 - val_loss: 0.5703 - val_accuracy: 0.7743\n",
      "Epoch 3/15\n",
      "215/215 [==============================] - 2s 11ms/step - loss: 0.5189 - accuracy: 0.8028 - val_loss: 0.5168 - val_accuracy: 0.7992\n",
      "Epoch 4/15\n",
      "215/215 [==============================] - 2s 11ms/step - loss: 0.4634 - accuracy: 0.8173 - val_loss: 0.4789 - val_accuracy: 0.7992\n",
      "Epoch 5/15\n",
      "215/215 [==============================] - 2s 11ms/step - loss: 0.4292 - accuracy: 0.8213 - val_loss: 0.4556 - val_accuracy: 0.8110\n",
      "Epoch 6/15\n",
      "215/215 [==============================] - 2s 11ms/step - loss: 0.4103 - accuracy: 0.8260 - val_loss: 0.4456 - val_accuracy: 0.8071\n",
      "Epoch 7/15\n",
      "215/215 [==============================] - 2s 11ms/step - loss: 0.3999 - accuracy: 0.8310 - val_loss: 0.4410 - val_accuracy: 0.8136\n",
      "Epoch 8/15\n",
      "215/215 [==============================] - 2s 11ms/step - loss: 0.3930 - accuracy: 0.8311 - val_loss: 0.4373 - val_accuracy: 0.8163\n",
      "Epoch 9/15\n",
      "215/215 [==============================] - 2s 11ms/step - loss: 0.3873 - accuracy: 0.8339 - val_loss: 0.4370 - val_accuracy: 0.8215\n",
      "Epoch 10/15\n",
      "215/215 [==============================] - 2s 11ms/step - loss: 0.3821 - accuracy: 0.8352 - val_loss: 0.4324 - val_accuracy: 0.8189\n",
      "Epoch 11/15\n",
      "215/215 [==============================] - 2s 11ms/step - loss: 0.3773 - accuracy: 0.8368 - val_loss: 0.4323 - val_accuracy: 0.8058\n",
      "Epoch 12/15\n",
      "215/215 [==============================] - 2s 11ms/step - loss: 0.3733 - accuracy: 0.8403 - val_loss: 0.4323 - val_accuracy: 0.8215\n",
      "Epoch 13/15\n",
      "215/215 [==============================] - 2s 11ms/step - loss: 0.3680 - accuracy: 0.8421 - val_loss: 0.4303 - val_accuracy: 0.8176\n",
      "Epoch 14/15\n",
      "215/215 [==============================] - 2s 11ms/step - loss: 0.3631 - accuracy: 0.8459 - val_loss: 0.4293 - val_accuracy: 0.8202\n",
      "Epoch 15/15\n",
      "215/215 [==============================] - 2s 11ms/step - loss: 0.3587 - accuracy: 0.8459 - val_loss: 0.4278 - val_accuracy: 0.8189\n"
     ]
    }
   ],
   "source": [
    "# Train a classifier on top of USE pretrained embeddings\n",
    "model_6_history = model_6.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=15,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
    "                                                                     \"tf_hub_sentence_encoder\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uDrKgxzuKhtC",
    "outputId": "2698d86c-b348-4e1d-9a0a-c4ae13316269"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2064],\n",
       "       [0.765 ],\n",
       "       [0.9727],\n",
       "       [0.1604],\n",
       "       [0.782 ],\n",
       "       [0.7563],\n",
       "       [0.974 ],\n",
       "       [0.968 ],\n",
       "       [0.9463],\n",
       "       [0.1194]], dtype=float16)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with USE TF Hub Model\n",
    "model_6_pred_probs = model_6.predict(val_sentences)\n",
    "model_6_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W3J2sShbKwfs",
    "outputId": "2b0b3ad5-7ad2-4dfb-adb3-28a690451e3e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float16, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float16)>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert prediction probabilities to labels\n",
    "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
    "model_6_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ph8KI1oNK4HD",
    "outputId": "cf351a8d-934b-40e7-e967-0c0124160c3a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 81.88976377952756,\n",
       " 'precision': 0.8203089036947304,\n",
       " 'recall': 0.8188976377952756,\n",
       " 'f1': 0.8177314483416845}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model 6 performance metrics\n",
    "model_6_results = calculate_results(y_true=val_labels,\n",
    "                                    y_pred=model_6_preds)\n",
    "model_6_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gg41ex0sLDoF"
   },
   "source": [
    "## Model 7: TF Hub Pretrained USE but with 10% of training data\n",
    "\n",
    "Transfer learning really helps when you don't have a large dataset.\n",
    "\n",
    "To see how our model performs on a smaller dataset, let's replicate `model_6` except we'll train it on 10% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "PZL8js9-M5oZ"
   },
   "outputs": [],
   "source": [
    "# ## NOTE: Making data splits like below leads to data leakage (model_7 trained on 10% data, outperforms model_6 trained on 100% data)\n",
    "# ## DO NOT MAKE DATA SPLITS WHICH LEAK DATA FROM VALIDATION/TEST SETS INTO TRAINING SET \n",
    "\n",
    "# # Create subsets of 10% of the training data\n",
    "# train_10_percent = train_df_shuffled[[\"text\", \"target\"]].sample(frac=0.1, random_state=42)\n",
    "# # train_10_percent.head(), len(train_10_percent)\n",
    "# train_sentences_10_percent = train_10_percent[\"text\"].to_list()\n",
    "# train_labels_10_percent = train_10_percent[\"target\"].to_list()\n",
    "# len(train_sentences_10_percent), len(train_labels_10_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "55bzxeJQUTC0"
   },
   "source": [
    "> üîë **Note:** Be *very* careful when creating training/val/test splits that you don't leak data across the datasets, otherwise your model evaluation metrics will be wrong. If something looks too good to be true (a model trained on 10% of data outperforming the same model trained on 100% of data) trust your gut and go back through to find where the error may lie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "CvoPRskfS8Pm"
   },
   "outputs": [],
   "source": [
    "# Making a better dataset split (no data leakage)\n",
    "train_10_percent_split = int(0.1 * len(train_sentences))\n",
    "train_sentences_10_percent = train_sentences[:train_10_percent_split]\n",
    "train_labels_10_percent = train_labels[:train_10_percent_split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oglhBYknTKAL",
    "outputId": "79a1930a-9003-411f-c74b-7c34115be4ba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    406\n",
       "1    279\n",
       "dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of each label in the updated training data subset\n",
    "pd.Series(np.array(train_labels_10_percent)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gGNtG6izNM80",
    "outputId": "89758ae9-297b-47fb-c2e5-6117fda39897"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4342\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of targets in our subset of data\n",
    "train_df_shuffled[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SjxT2OEjOzm2"
   },
   "source": [
    "To recreate a model the same as a previous model you've created you can use the `tf.keras.models.clone_model()` method, see more here: https://www.tensorflow.org/api_docs/python/tf/keras/models/clone_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GTAkNUBvNjBx",
    "outputId": "92edfc47-e72a-45a6-e202-48b7d8ebe2a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7_USE\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " USE (KerasLayer)            (None, 512)               256797824 \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                32832     \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256,830,721\n",
      "Trainable params: 32,897\n",
      "Non-trainable params: 256,797,824\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Let's build a model the same as model_6\n",
    "# model_7 = tf.keras.models.clone_model(model_6)\n",
    "model_7 = tf.keras.Sequential([\n",
    "  sentence_encoder_layer,\n",
    "  layers.Dense(64, activation=\"relu\"),\n",
    "  layers.Dense(1, activation=\"sigmoid\", name=\"output_layer\")                               \n",
    "], name=\"model_7_USE\")\n",
    "\n",
    "# Compile model\n",
    "model_7.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# Get a summary (will be same as model_6)\n",
    "model_7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Egc7fLk9N-JP",
    "outputId": "bdb257d3-275c-45aa-f4cb-48c3cbc4a694"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder_10_percent_correct_split/20220507-181432\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 2s 35ms/step - loss: 0.6661 - accuracy: 0.7124 - val_loss: 0.6451 - val_accuracy: 0.7454\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.5935 - accuracy: 0.8088 - val_loss: 0.5879 - val_accuracy: 0.7598\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.5212 - accuracy: 0.8175 - val_loss: 0.5331 - val_accuracy: 0.7717\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.4621 - accuracy: 0.8204 - val_loss: 0.5050 - val_accuracy: 0.7703\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.4219 - accuracy: 0.8336 - val_loss: 0.4932 - val_accuracy: 0.7808\n"
     ]
    }
   ],
   "source": [
    "# Fit the model to the 10% training data subsets\n",
    "model_7_history = model_7.fit(train_sentences_10_percent,\n",
    "                              train_labels_10_percent,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
    "                                                                     \"tf_hub_sentence_encoder_10_percent_correct_split\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZzQaiu_kQH22",
    "outputId": "37c2df76-d40c-4d50-d909-cf93622c4133"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2153],\n",
       "       [0.6094],\n",
       "       [0.92  ],\n",
       "       [0.39  ],\n",
       "       [0.5493],\n",
       "       [0.6855],\n",
       "       [0.8843],\n",
       "       [0.784 ],\n",
       "       [0.833 ],\n",
       "       [0.1656]], dtype=float16)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with the model trained on 10% of the data\n",
    "model_7_pred_probs = model_7.predict(val_sentences)\n",
    "model_7_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ma3xidC1QTL1",
    "outputId": "66a1f341-49a9-4961-8862-c581baa00a19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float16, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float16)>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn pred probs into labels\n",
    "model_7_preds = tf.squeeze(tf.round(model_7_pred_probs))\n",
    "model_7_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JG4rtLi2QcTm",
    "outputId": "953ca2af-ca9b-42e4-8375-95a8f3ee0ca7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 78.08398950131233,\n",
       " 'precision': 0.7831507995990558,\n",
       " 'recall': 0.7808398950131233,\n",
       " 'f1': 0.7786634307220067}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evalaute model 7 predictions\n",
    "model_7_results = calculate_results(y_true=val_labels,\n",
    "                                    y_pred=model_7_preds)\n",
    "model_7_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26PsF3DuRQrt"
   },
   "source": [
    "## Comparing the peformance of each of our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "id": "MgI0SBZMVSnQ",
    "outputId": "e8442e34-6e5e-4b4d-f249-94634e25bf81"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0_baseline</th>\n",
       "      <td>79.265092</td>\n",
       "      <td>0.811139</td>\n",
       "      <td>0.792651</td>\n",
       "      <td>0.786219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_simple_dense</th>\n",
       "      <td>77.821522</td>\n",
       "      <td>0.781410</td>\n",
       "      <td>0.778215</td>\n",
       "      <td>0.775608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_lstm</th>\n",
       "      <td>77.165354</td>\n",
       "      <td>0.771296</td>\n",
       "      <td>0.771654</td>\n",
       "      <td>0.771132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_gru</th>\n",
       "      <td>78.346457</td>\n",
       "      <td>0.785020</td>\n",
       "      <td>0.783465</td>\n",
       "      <td>0.781680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_bidirectional</th>\n",
       "      <td>77.821522</td>\n",
       "      <td>0.779199</td>\n",
       "      <td>0.778215</td>\n",
       "      <td>0.776621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5_conv1d</th>\n",
       "      <td>77.034121</td>\n",
       "      <td>0.772078</td>\n",
       "      <td>0.770341</td>\n",
       "      <td>0.768193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6_tf_hub_use_encoder</th>\n",
       "      <td>81.889764</td>\n",
       "      <td>0.820309</td>\n",
       "      <td>0.818898</td>\n",
       "      <td>0.817731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7_tf_hub_use_encoder_10_percent</th>\n",
       "      <td>78.083990</td>\n",
       "      <td>0.783151</td>\n",
       "      <td>0.780840</td>\n",
       "      <td>0.778663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  accuracy  precision    recall        f1\n",
       "0_baseline                       79.265092   0.811139  0.792651  0.786219\n",
       "1_simple_dense                   77.821522   0.781410  0.778215  0.775608\n",
       "2_lstm                           77.165354   0.771296  0.771654  0.771132\n",
       "3_gru                            78.346457   0.785020  0.783465  0.781680\n",
       "4_bidirectional                  77.821522   0.779199  0.778215  0.776621\n",
       "5_conv1d                         77.034121   0.772078  0.770341  0.768193\n",
       "6_tf_hub_use_encoder             81.889764   0.820309  0.818898  0.817731\n",
       "7_tf_hub_use_encoder_10_percent  78.083990   0.783151  0.780840  0.778663"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine model results into a DataFrame\n",
    "all_model_results = pd.DataFrame({\"0_baseline\": baseline_results,\n",
    "                                  \"1_simple_dense\": model_1_results,\n",
    "                                  \"2_lstm\": model_2_results,\n",
    "                                  \"3_gru\": model_3_results,\n",
    "                                  \"4_bidirectional\": model_4_results,\n",
    "                                  \"5_conv1d\": model_5_results,\n",
    "                                  \"6_tf_hub_use_encoder\": model_6_results,\n",
    "                                  \"7_tf_hub_use_encoder_10_percent\": model_7_results})\n",
    "all_model_results = all_model_results.transpose()\n",
    "all_model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "ecgLCp4IVkOX"
   },
   "outputs": [],
   "source": [
    "# Reduce the accuracy to the same scale as other metrics\n",
    "all_model_results[\"accuracy\"] = all_model_results[\"accuracy\"]/100\n",
    "# all_model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 590
    },
    "id": "LprTMBfQWckZ",
    "outputId": "8c8636f4-7731-4695-d966-973deb9a1872"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot and compare all of the model results\n",
    "all_model_results.plot(kind=\"bar\", figsize=(10, 7)).legend(bbox_to_anchor=(1.0, 1.0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 590
    },
    "id": "xASFWi98W0Ve",
    "outputId": "86dfb223-0217-4e32-f353-ec0147d87241"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sort model results by f1-score\n",
    "all_model_results.sort_values(\"f1\", ascending=False)[\"f1\"].plot(kind=\"bar\", figsize=(10, 7));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S8v7tXJ1XrWl"
   },
   "source": [
    "## Uploading our model training logs to TesnorBoard.dev\n",
    "We can further inspect our model's performance using TensorBoard.dev: https://tensorboard.dev/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "iN5nWpwqYNNt"
   },
   "outputs": [],
   "source": [
    "# # View TensorBoard logs of transfer learning modelling experiments (plus all of our other models)\n",
    "# # Upload TensorBoard dev records\n",
    "# !tensorboard dev upload --logdir ./model_logs/ \\\n",
    "#   --name \"NLP Modelling Experiments ZTM TF Course Video\" \\\n",
    "#   --description \"Comparing multiple different types of model architectures on the Kaggle Tweets text classification dataset\" \\\n",
    "#   --one_shot # exit the uploader once uploading is finished"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eE9WoH_nZsMb"
   },
   "source": [
    "Now I've ran the cell above, my modelling experiments are visable on TensorBoard.dev: https://tensorboard.dev/experiment/Eacboed3RbKPWIGcXe1Z6g/\n",
    "\n",
    "> üìñ **Resource:** TensorBoard is great for quickly tracking experiments but for larger scale experiments and a whole bunch more tracking options, check out Weights & Biases: https://wandb.ai/site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "OEVX02N5aiyp"
   },
   "outputs": [],
   "source": [
    "# # See the previous TensorBoard Dev experiments you've run...\n",
    "# !tensorboard dev list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "cXTfCURJZbts"
   },
   "outputs": [],
   "source": [
    "# If you need to delete an experiment from TensorBoard, you can run the following:\n",
    "# !tensorboard dev delete --experiment_id Eacboed3RbKPWIGcXe1Z6gB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iV-oY5X6bmCh"
   },
   "source": [
    "## Saving and loading a trained model \n",
    "\n",
    "There are two main formats to save a model to in TensorFlow:\n",
    "1. The HDF5 format\n",
    "2. The `SavedModel` format (this is the default when using TensorFlow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "8NuJcP0G-d_0"
   },
   "outputs": [],
   "source": [
    "# Save TF Hub Sentence Encoder model to HDF5 format\n",
    "model_6.save(\"model_6.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "83dzH-v6-vPP"
   },
   "outputs": [],
   "source": [
    "# Load model with custom Hub Layer (required HDF5 format)\n",
    "import tensorflow_hub as hub\n",
    "loaded_model_6 = tf.keras.models.load_model(\"model_6.h5\",\n",
    "                                            custom_objects={\"KerasLayer\": hub.KerasLayer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6zSLAatG_Xg0",
    "outputId": "971c0149-62cd-403d-81f1-139d549e88aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 9ms/step - loss: 0.4278 - accuracy: 0.8189\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4277741014957428, 0.8188976645469666]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How does our loaded model perform?\n",
    "loaded_model_6.evaluate(val_sentences, val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iUXdwTKJ_mmC"
   },
   "source": [
    "Now let's save to the `SavedModel` format... (see more on this here: https://www.tensorflow.org/tutorials/keras/save_and_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KH56jDFz_2T5",
    "outputId": "bfd21ffe-af2d-4ec2-c0df-7dc5a65b9d4a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-07 18:14:44.330045: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) USE_input with unsupported characters which will be renamed to use_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_6_SavedModel_format/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_6_SavedModel_format/assets\n"
     ]
    }
   ],
   "source": [
    "# Save TF Hub Sentence Ecnoder model to SavedModel format (default)\n",
    "model_6.save(\"model_6_SavedModel_format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8KncUg_M_9gz",
    "outputId": "19e677b4-a123-475e-d104-e56b0418a82b"
   },
   "outputs": [],
   "source": [
    "# Load in a model from the SavedModel format\n",
    "loaded_model_6_SavedModel_format = tf.keras.models.load_model(\"model_6_SavedModel_format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YPDGs88WAWaP",
    "outputId": "5be41b6e-e202-4585-bb88-8f6eaf23c3f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 9ms/step - loss: 0.4278 - accuracy: 0.8189\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4277741014957428, 0.8188976645469666]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate model in SavedModel format\n",
    "loaded_model_6_SavedModel_format.evaluate(val_sentences, val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sPHYDcL-AbzG"
   },
   "source": [
    "## Finding the most wrong examples\n",
    "\n",
    "* If our best model still isn't perfect, what examples is it getting wrong?\n",
    "* And of these wrong examples which ones is it getting *most* wrong (those will predicition probabilities closest to the opposite class)\n",
    "\n",
    "For example if a sample should have a label of 0 but our model predicts a prediction probability of 0.999 (really close to 1) and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XgSL1VH2CHBu",
    "outputId": "601f485a-39d8-4e40-d2d0-021a6627f3f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-05-07 18:14:53--  https://storage.googleapis.com/ztm_tf_course/08_model_6_USE_feature_extractor.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.114.128, 142.250.113.128, 142.251.116.128, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.114.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 960779165 (916M) [application/zip]\n",
      "Saving to: ‚Äò08_model_6_USE_feature_extractor.zip‚Äô\n",
      "\n",
      "08_model_6_USE_feat 100%[===================>] 916.27M  50.4MB/s    in 19s     \n",
      "\n",
      "2022-05-07 18:15:12 (49.4 MB/s) - ‚Äò08_model_6_USE_feature_extractor.zip‚Äô saved [960779165/960779165]\n",
      "\n",
      "Archive:  08_model_6_USE_feature_extractor.zip\n",
      "   creating: 08_model_6_USE_feature_extractor/\n",
      "   creating: 08_model_6_USE_feature_extractor/assets/\n",
      "   creating: 08_model_6_USE_feature_extractor/variables/\n",
      "  inflating: 08_model_6_USE_feature_extractor/variables/variables.data-00000-of-00001  \n",
      "  inflating: 08_model_6_USE_feature_extractor/variables/variables.index  \n",
      "  inflating: 08_model_6_USE_feature_extractor/saved_model.pb  \n"
     ]
    }
   ],
   "source": [
    "# Download a pretrained model from Google Storage\n",
    "!wget https://storage.googleapis.com/ztm_tf_course/08_model_6_USE_feature_extractor.zip\n",
    "!unzip 08_model_6_USE_feature_extractor.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9OTLTVMSCkbL",
    "outputId": "dd15fa49-c139-400c-ea49-52f485945e3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 9ms/step - loss: 0.4272 - accuracy: 0.8163\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.42723074555397034, 0.8162729740142822]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import previously trained model from Google Storage\n",
    "model_6_pretrained = tf.keras.models.load_model(\"08_model_6_USE_feature_extractor\")\n",
    "model_6_pretrained.evaluate(val_sentences, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ML3jOCvCzW8",
    "outputId": "446da531-9ead-4671-a990-efcdb9207296"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with the loaded model from GS\n",
    "model_6_pretrained_pred_probs = model_6_pretrained.predict(val_sentences)\n",
    "model_6_pretrained_preds = tf.squeeze(tf.round(model_6_pretrained_pred_probs))\n",
    "model_6_pretrained_preds[:10] # these should be in label format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "nwa_Bk9nB4Tl",
    "outputId": "423ea869-96d0-4d5e-872b-941e9f203a81"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DFR EP016 Monthly Meltdown - On Dnbheaven 2015...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.159816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FedEx no longer to transport bioterror germs i...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.747282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gunmen kill four in El Salvador bus attack: Su...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@camilacabello97 Internally and externally scr...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.196245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Radiation emergency #preparedness starts with ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.707664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  pred  pred_prob\n",
       "0  DFR EP016 Monthly Meltdown - On Dnbheaven 2015...       0   0.0   0.159816\n",
       "1  FedEx no longer to transport bioterror germs i...       0   1.0   0.747282\n",
       "2  Gunmen kill four in El Salvador bus attack: Su...       1   1.0   0.988755\n",
       "3  @camilacabello97 Internally and externally scr...       1   0.0   0.196245\n",
       "4  Radiation emergency #preparedness starts with ...       1   1.0   0.707664"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrame with validation sentences, validation labels and best performing model prediction labels + probabilities\n",
    "val_df = pd.DataFrame({\"text\": val_sentences,\n",
    "                       \"target\": val_labels,\n",
    "                       \"pred\": model_6_pretrained_preds,\n",
    "                       \"pred_prob\": tf.squeeze(model_6_pretrained_pred_probs)})\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "id": "inTan9xLDaj1",
    "outputId": "979772a5-9093-4d71-cc4a-fe08cce1ef88"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>? High Skies - Burning Buildings ? http://t.co...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.910294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>FedEx will no longer transport bioterror patho...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.876936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>@noah_anyname That's where the concentration c...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.852329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>Ashes 2015: Australia¬â√õ¬™s collapse at Trent Br...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.835692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>@AshGhebranious civil rights continued in the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.827275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>@SonofLiberty357 all illuminated by the bright...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.814787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.811048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>@madonnamking RSPCA site multiple 7 story high...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.803179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>@freefromwolves GodsLove &amp;amp; #thankU brother...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.766963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>Air Group is here to the rescue! We have 24/7 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.766902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  target  pred  \\\n",
       "31   ? High Skies - Burning Buildings ? http://t.co...       0   1.0   \n",
       "759  FedEx will no longer transport bioterror patho...       0   1.0   \n",
       "628  @noah_anyname That's where the concentration c...       0   1.0   \n",
       "209  Ashes 2015: Australia¬â√õ¬™s collapse at Trent Br...       0   1.0   \n",
       "251  @AshGhebranious civil rights continued in the ...       0   1.0   \n",
       "393  @SonofLiberty357 all illuminated by the bright...       0   1.0   \n",
       "109  [55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...       0   1.0   \n",
       "49   @madonnamking RSPCA site multiple 7 story high...       0   1.0   \n",
       "119  @freefromwolves GodsLove &amp; #thankU brother...       0   1.0   \n",
       "344  Air Group is here to the rescue! We have 24/7 ...       0   1.0   \n",
       "\n",
       "     pred_prob  \n",
       "31    0.910294  \n",
       "759   0.876936  \n",
       "628   0.852329  \n",
       "209   0.835692  \n",
       "251   0.827275  \n",
       "393   0.814787  \n",
       "109   0.811048  \n",
       "49    0.803179  \n",
       "119   0.766963  \n",
       "344   0.766902  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the wrong predictions and sort by prediction probabilities\n",
    "most_wrong = val_df[val_df[\"target\"] != val_df[\"pred\"]].sort_values(\"pred_prob\", ascending=False)\n",
    "most_wrong[:10] # these are false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "PQV_SFoSESI1",
    "outputId": "8af9a512-1cdc-4317-e089-d3e4f88e649f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>@SoonerMagic_ I mean I'm a fan but I don't nee...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>I get to smoke my shit in peace</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Why are you deluged with low self-image? Take ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.039012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>Reddit Will Now Quarantine¬â√õ_ http://t.co/pkUA...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Ron &amp;amp; Fez - Dave's High School Crush https...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  target  pred  \\\n",
       "411  @SoonerMagic_ I mean I'm a fan but I don't nee...       1   0.0   \n",
       "233                    I get to smoke my shit in peace       1   0.0   \n",
       "38   Why are you deluged with low self-image? Take ...       1   0.0   \n",
       "244  Reddit Will Now Quarantine¬â√õ_ http://t.co/pkUA...       1   0.0   \n",
       "23   Ron &amp; Fez - Dave's High School Crush https...       1   0.0   \n",
       "\n",
       "     pred_prob  \n",
       "411   0.043940  \n",
       "233   0.042157  \n",
       "38    0.039012  \n",
       "244   0.038968  \n",
       "23    0.037179  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_wrong.tail() # these are false negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_1Me95bIEH75"
   },
   "source": [
    "Let's remind ourselves of the target labels...\n",
    "* `0` = not diaster\n",
    "* `1` = diaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UhUESFzvDhqF",
    "outputId": "2fa10a18-25fa-42d5-e72d-968e02e79b06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 0, Pred: 1.0, Prob: 0.9102941155433655\n",
      "Text:\n",
      "? High Skies - Burning Buildings ? http://t.co/uVq41i3Kx2 #nowplaying\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1.0, Prob: 0.8769360184669495\n",
      "Text:\n",
      "FedEx will no longer transport bioterror pathogens in wake of anthrax lab mishaps http://t.co/lHpgxc4b8J\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1.0, Prob: 0.8523291945457458\n",
      "Text:\n",
      "@noah_anyname That's where the concentration camps and mass murder come in. \n",
      " \n",
      "EVERY. FUCKING. TIME.\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1.0, Prob: 0.835692286491394\n",
      "Text:\n",
      "Ashes 2015: Australia¬â√õ¬™s collapse at Trent Bridge among worst in history: England bundled out Australia for 60 ... http://t.co/t5TrhjUAU0\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1.0, Prob: 0.8272749781608582\n",
      "Text:\n",
      "@AshGhebranious civil rights continued in the 60s. And what about trans-generational trauma? if anything we should listen to the Americans.\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1.0, Prob: 0.814786970615387\n",
      "Text:\n",
      "@SonofLiberty357 all illuminated by the brightly burning buildings all around the town!\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1.0, Prob: 0.8110477328300476\n",
      "Text:\n",
      "[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES WITH MAGNE-TRACTION INSTRUCTIONS http://t.co/xEZBs3sq0y http://t.co/C2x0QoKGlY\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1.0, Prob: 0.803179144859314\n",
      "Text:\n",
      "@madonnamking RSPCA site multiple 7 story high rise buildings next to low density character residential in an area that floods\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1.0, Prob: 0.7669633030891418\n",
      "Text:\n",
      "@freefromwolves GodsLove &amp; #thankU brother Danny for RT of NEW VIDEO http://t.co/cybKsXHF7d The Coming Apocalyptic US Earthquake &amp; Tsunami\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1.0, Prob: 0.7669023275375366\n",
      "Text:\n",
      "Air Group is here to the rescue! We have 24/7 Emergency Service! Learn more about it here - http://t.co/9lyx7zMtHE http://t.co/5PbC96rTMJ\n",
      "\n",
      "----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the false positives (model predicted 1 when should've been 0)\n",
    "for row in most_wrong[:10].itertuples():\n",
    "  _, text, target, pred, pred_prob = row\n",
    "  print(f\"Target: {target}, Pred: {pred}, Prob: {pred_prob}\")\n",
    "  print(f\"Text:\\n{text}\\n\")\n",
    "  print(\"----\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-T4lJhV6Fcxa",
    "outputId": "0a4a7b68-9351-42ee-a95f-75d4100d2078"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 1, Pred: 0.0, Prob: 0.06732601672410965\n",
      "Text:\n",
      "@DavidVonderhaar At least you were sincere ??\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0.0, Prob: 0.05504606291651726\n",
      "Text:\n",
      "@willienelson We need help! Horses will die!Please RT &amp; sign petition!Take a stand &amp; be a voice for them! #gilbert23 https://t.co/e8dl1lNCVu\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0.0, Prob: 0.05460943281650543\n",
      "Text:\n",
      "going to redo my nails and watch behind the scenes of desolation of smaug ayyy\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0.0, Prob: 0.05460492521524429\n",
      "Text:\n",
      "Lucas Duda is Ghost Rider. Not the Nic Cage version but an actual 'engulfed in flames' badass. #Mets\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0.0, Prob: 0.049619752913713455\n",
      "Text:\n",
      "You can never escape me. Bullets don't harm me. Nothing harms me. But I know pain. I know pain. Sometimes I share it. With someone like you.\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0.0, Prob: 0.043940469622612\n",
      "Text:\n",
      "@SoonerMagic_ I mean I'm a fan but I don't need a girl sounding off like a damn siren\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0.0, Prob: 0.042157258838415146\n",
      "Text:\n",
      "I get to smoke my shit in peace\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0.0, Prob: 0.03901165351271629\n",
      "Text:\n",
      "Why are you deluged with low self-image? Take the quiz: http://t.co/XsPqdOrIqj http://t.co/CQYvFR4UCy\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0.0, Prob: 0.0389680340886116\n",
      "Text:\n",
      "Reddit Will Now Quarantine¬â√õ_ http://t.co/pkUAMXw6pm #onlinecommunities #reddit #amageddon #freespeech #Business http://t.co/PAWvNJ4sAP\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0.0, Prob: 0.037178732454776764\n",
      "Text:\n",
      "Ron &amp; Fez - Dave's High School Crush https://t.co/aN3W16c8F6 via @YouTube\n",
      "\n",
      "----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the false negatives (model predicted 0 when should've been 1)\n",
    "for row in most_wrong[-10:].itertuples():\n",
    "  _, text, target, pred, pred_prob = row\n",
    "  print(f\"Target: {target}, Pred: {pred}, Prob: {pred_prob}\")\n",
    "  print(f\"Text:\\n{text}\\n\")\n",
    "  print(\"----\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Myh5WDGiGC_J"
   },
   "source": [
    "## Making predictions on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h_adHc7tGh6z",
    "outputId": "4be5873c-870a-4fef-a294-f2fdd16f9f26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: 1, Prob: 0.9824736714363098\n",
      "Text:\n",
      "Hundreds of migrants feared drowned off Libya: http://t.co/RTx4O0SIyH #news #bbc #cnn #msnbc #nyt #tcot #tlot #waar #ccot #ctot #p2 #ap\n",
      "\n",
      "-----\n",
      "\n",
      "Pred: 1, Prob: 0.9478476643562317\n",
      "Text:\n",
      "Geoengineering and burning of fossil fuels is making our global weather unstable. With temps up to 165√•¬° and biggest flood in past 200 years\n",
      "\n",
      "-----\n",
      "\n",
      "Pred: 0, Prob: 0.19750086963176727\n",
      "Text:\n",
      "Your brain is particularly vulnerable to trauma at two distinct ages http://t.co/Wvq0Rf6UAm\n",
      "\n",
      "-----\n",
      "\n",
      "Pred: 0, Prob: 0.17268764972686768\n",
      "Text:\n",
      "*Ears bleeding from the bass* https://t.co/d5RrrwHjpN\n",
      "\n",
      "-----\n",
      "\n",
      "Pred: 1, Prob: 0.5969299077987671\n",
      "Text:\n",
      "How do I step outside for 5 seconds and get annihilated  by mosquitoes?\n",
      "\n",
      "-----\n",
      "\n",
      "Pred: 1, Prob: 0.9828296303749084\n",
      "Text:\n",
      "#WorldNews #World\n",
      " Saipan Has No Water Electricity in Typhoon Aftermath - Voice of America - World - Google News.. http://t.co/5sUdXgNdA3\n",
      "\n",
      "-----\n",
      "\n",
      "Pred: 0, Prob: 0.1405194103717804\n",
      "Text:\n",
      "The legendary dutch producer Dannic is making his way to Denver to bring his progessive house sound to... http://t.co/s3JhXiDslZ\n",
      "\n",
      "-----\n",
      "\n",
      "Pred: 0, Prob: 0.08618304878473282\n",
      "Text:\n",
      "#callofduty #advancedwarfare COD Advanced Warfare Reckoning DLC 4 Quarantine Gameplay http://t.co/huNMYHyAHp\n",
      "\n",
      "-----\n",
      "\n",
      "Pred: 1, Prob: 0.806254506111145\n",
      "Text:\n",
      "Man injured in Radcliff shooting http://t.co/3iYXOoaCW6\n",
      "\n",
      "-----\n",
      "\n",
      "Pred: 1, Prob: 0.8494228720664978\n",
      "Text:\n",
      "The meltdown I'm currently witnessing makes it seem like a delayed flight is a true anomaly instead of y'know the expected outcome.\n",
      "\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Making predictions on the test dataset and visualizing them\n",
    "test_sentences = test_df[\"text\"].to_list()\n",
    "test_samples = random.sample(test_sentences, 10)\n",
    "for test_sample in test_samples:\n",
    "  pred_prob = tf.squeeze(model_6_pretrained.predict([test_sample])) # our model expects a list as input\n",
    "  pred = tf.round(pred_prob)\n",
    "  print(f\"Pred: {int(pred)}, Prob: {pred_prob}\")\n",
    "  print(f\"Text:\\n{test_sample}\\n\")\n",
    "  print(\"-----\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h1ARtfoAHQf_"
   },
   "source": [
    "## Your challenge... predicting on Tweets from the wild\n",
    "\n",
    "Go to your favourite Twitter account and copy one of their latest Tweets.\n",
    "\n",
    "Then pass that Tweet through our trained model.\n",
    "\n",
    "Is that Tweet a disaster or not disaster (according to the model)? Is the model right or wrong?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VN-XJuilI1ls"
   },
   "source": [
    "## The speed/score tradeoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "AIJrWpSfJ9X0"
   },
   "outputs": [],
   "source": [
    "# Let's make a function to measure the time of prediction\n",
    "import time\n",
    "def pred_timer(model, samples):\n",
    "  \"\"\"\n",
    "  Times how long a model takes to make predictions on samples.\n",
    "  \"\"\"\n",
    "  start_time = time.perf_counter() # get start time\n",
    "  model.predict(samples) # make predictions\n",
    "  end_time = time.perf_counter() # get finish time\n",
    "  total_time = end_time-start_time # calculuate how long predictons took to make\n",
    "  time_per_pred = total_time/len(samples)\n",
    "  return total_time, time_per_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8NjtO6ZnKAk8",
    "outputId": "4dfd5e5e-e814-4802-a39a-b8b6f572284c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.20879595200131007, 0.0002740104356972573)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate TF Hub Sentence Encoder time per pred\n",
    "model_6_total_pred_time, model_6_time_per_pred = pred_timer(model=model_6_pretrained,\n",
    "                                                            samples=val_sentences)\n",
    "model_6_total_pred_time, model_6_time_per_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QviAtHxrKBYL",
    "outputId": "6c1f4e96-275a-412d-ce34-0abb5d9b4634"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.012262755999472574, 1.609285564235246e-05)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate our baseline model times per pred\n",
    "baseline_total_pred_time, baseline_time_per_pred = pred_timer(model_0, val_sentences)\n",
    "baseline_total_pred_time, baseline_time_per_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XpVh0HV7LsAc",
    "outputId": "d6884e12-6891-45bf-bc40-c981954beaed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 81.62729658792651,\n",
       " 'precision': 0.818446310697231,\n",
       " 'recall': 0.8162729658792651,\n",
       " 'f1': 0.8148082644367335}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get results for pretrained GS model\n",
    "model_6_pretrained_results = calculate_results(y_true=val_labels,\n",
    "                                               y_pred=model_6_pretrained_preds)\n",
    "model_6_pretrained_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "3JHbdjJiLaUP",
    "outputId": "02ae01e0-70fc-4980-89fb-aaa4cbee2fac"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.scatter(baseline_time_per_pred, baseline_results[\"f1\"], label=\"baseline\")\n",
    "plt.scatter(model_6_time_per_pred, model_6_pretrained_results[\"f1\"], label=\"tf_hub_sentence_encoder\")\n",
    "plt.legend()\n",
    "plt.title(\"F1-score versus time per prediction\")\n",
    "plt.xlabel(\"Time per prediction\")\n",
    "plt.ylabel(\"F1-score\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OTS1fYADMQs3"
   },
   "source": [
    "> üìñ **Resource:** See all course materials as well as exercises and extra-curriculum for this notebook on GitHub: https://github.com/mrdbourke/tensorflow-deep-learning"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNKOCtVw0yctgwcHu2wrFF+",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "08_introduction_to_nlp_in_tensorflow_video.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
